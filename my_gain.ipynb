{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1500) loss D 0.177 loss G 0.913: 100%|██████████| 2000/2000 [06:48<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def generate_mask(data, miss_rate):\n",
    "    dim = data.shape[1]\n",
    "    size = data.shape[0]\n",
    "    A = np.random.uniform(0., 1., size=(size,dim))\n",
    "    B = A > miss_rate\n",
    "    mask = 1. * B\n",
    "\n",
    "    return mask\n",
    "\n",
    "def generate_hint(mask, hint_rate):\n",
    "    hint_mask = generate_mask(mask, 1-hint_rate)\n",
    "    hint = mask * hint_mask \n",
    "\n",
    "    return hint\n",
    "\n",
    "\n",
    "def update_D(batch, mask, hint, Z, net_D, net_G, loss, optimizer_D, alpha):\n",
    "    batch_size = batch.shape[0]\n",
    "    \n",
    "    ones = torch.ones_like(batch)\n",
    "    zeros = torch.zeros_like (batch)\n",
    "\n",
    "    #ones = torch.ones(batch_size)\n",
    "    #zeros = torch.zeros(batch_size)\n",
    "    \n",
    "    new_X = mask * batch + (1-mask) * Z\n",
    "    optimizer_D.zero_grad()\n",
    "    \n",
    "    input_D = torch.cat((batch, hint), 1).float()\n",
    "    input_G = torch.cat((new_X, mask), 1).float()\n",
    "\n",
    "\n",
    "    real_Y = net_D(input_D)\n",
    "    #print(real_Y)\n",
    "    sample_G = net_G(input_G)\n",
    "    fake_X = new_X * mask + sample_G * (1-mask)\n",
    "    fake_input_D = torch.cat((fake_X.detach(), hint), 1).float()\n",
    "    fake_Y = net_D(fake_input_D)\n",
    "    \n",
    "    loss_D = (loss(fake_Y.float(), mask.float()) ).mean()\n",
    "    loss_D.backward()\n",
    "\n",
    "    optimizer_D.step()\n",
    "\n",
    "    return loss_D\n",
    "\n",
    "def update_G(batch, mask, hint, Z, net_D, net_G, loss, optimizer_G, alpha):\n",
    "    \n",
    "    loss_mse = nn.MSELoss(reduction = 'none')\n",
    "    \n",
    "    batch_size = Z.shape[0]\n",
    "\n",
    "    ones = torch.ones_like(batch)\n",
    "    #ones = torch.ones(batch_size)\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    new_X = mask * batch + (1-mask) * Z \n",
    "    input_G = torch.cat((new_X, mask), 1).float()\n",
    "    sample_G = net_G(input_G)\n",
    "    fake_X = new_X * mask + sample_G * (1-mask)\n",
    "\n",
    "    fake_input_D = torch.cat((fake_X, hint), 1).float()\n",
    "    fake_Y = net_D(fake_input_D)\n",
    "\n",
    "    loss_G = (loss(fake_Y, ones.reshape(fake_Y.shape).float()) * (1-mask) ).mean() + alpha * ( loss_mse((sample_G*mask).float(), (batch*mask).float()) ).mean() / torch.mean(mask) \n",
    "    loss_G.backward()\n",
    "\n",
    "    optimizer_G.step()\n",
    "\n",
    "    return loss_G\n",
    "\n",
    "\n",
    "def train(net_D, net_G, lr_D, lr_G, data_iter, num_epochs, data, hint_rate, alpha):\n",
    "    dim = data.shape[1]\n",
    "    size = data.shape[0]\n",
    "    \n",
    "    #loss = nn.BCEWithLogitsLoss(reduction = 'sum')\n",
    "    loss = nn.BCELoss(reduction = 'none')\n",
    "\n",
    "    loss_D_values = np.zeros(num_epochs)\n",
    "    loss_G_values = np.zeros(num_epochs)\n",
    "     \n",
    "    #for w in net_D.parameters():\n",
    "    #    nn.init.normal_(w, 0, 0.02)\n",
    "    #for w in net_G.parameters():\n",
    "    #    nn.init.normal_(w, 0, 0.02)\n",
    "\n",
    "    # Initialize weights for net_D\n",
    "    for name, param in net_D.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "\n",
    "    # Initialize weights for net_G\n",
    "    for name, param in net_G.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "    #optimizer_D = torch.optim.SGD(net_D.parameters(), lr = lr_D)\n",
    "    #optimizer_G = torch.optim.SGD(net_G.parameters(), lr = lr_G)\n",
    "\n",
    "    optimizer_D = torch.optim.Adam(net_D.parameters(), lr = lr_D)\n",
    "    optimizer_G = torch.optim.Adam(net_G.parameters(), lr = lr_G)\n",
    "\n",
    "    \n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for epoch in pbar:\n",
    "        \n",
    "        for batch in data_iter:\n",
    "            batch_size = batch.shape[0]\n",
    "\n",
    "            mask = torch.from_numpy(np.where(batch == 0, 0.0, 1.0))\n",
    "            hint = generate_hint(mask, hint_rate)\n",
    "\n",
    "            #Z = torch.normal(0, 1, size=(batch_size, dim))\n",
    "            Z = torch.rand((batch_size, dim)) / 0.01\n",
    "            loss_D = update_D(batch, mask, hint, Z, net_D, net_G, loss, optimizer_D, alpha)\n",
    "            loss_G = update_G(batch, mask, hint, Z, net_D, net_G, loss, optimizer_G, alpha)\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            s = \"{:6d}) loss D {:0.3f} loss G {:0.3f}\".format(\n",
    "                epoch,\n",
    "                loss_D.detach().numpy(),\n",
    "                loss_G.detach().numpy())\n",
    "            pbar.clear()\n",
    "            #logger.info('{}'.format(s))\n",
    "            pbar.set_description(s)\n",
    "\n",
    "        loss_D_values[epoch] = loss_D.detach().numpy()\n",
    "        loss_G_values[epoch] = loss_G.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "        #Z = torch.normal(0,1,(size, dim))\n",
    "        Z = torch.rand((size, dim)) / 0.01\n",
    "\n",
    "        mask = torch.from_numpy(np.where(data == 0, 0.0, 1.0))\n",
    "        hint = generate_hint(mask, hint_rate)\n",
    "\n",
    "        new_X = mask * data + (1-mask) * Z \n",
    "        input_G = torch.cat((new_X, mask), 1).float()\n",
    "        sample_G = net_G(input_G)\n",
    "\n",
    "        fake_X = torch.from_numpy(data) * mask + sample_G * (1-mask)\n",
    "        #fake_X = data * mask + sample_G * (1-mask)\n",
    "\n",
    "    df = pd.DataFrame(fake_X.detach().numpy())\n",
    "    #df.to_csv(\"my_imputed.csv\", index = False)\n",
    "    df.to_csv(\"imputed_dist2.csv\", index = False)\n",
    "\n",
    "    df_loss_D = pd.DataFrame(loss_D_values)\n",
    "    df_loss_D.to_csv(\"loss_D.csv\", index = False)\n",
    "    df_loss_G = pd.DataFrame(loss_G_values)\n",
    "    df_loss_G.to_csv(\"loss_G.csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    lr_D = trial.suggest_uniform('lr_D', 0.0001, 0.1 )\n",
    "    lr_G = trial.suggest_uniform('lr_G', 0.0001, 0.1 )\n",
    "\n",
    "    miss_rate = 0.2\n",
    "    hint_rate = trial.suggest_uniform('hint_rate', 0.0, 0.9 )\n",
    "    alpha = trial.suggest_uniform('alpha', 0, 0.5 )\n",
    "\n",
    "    batch_size = 128\n",
    "    num_epochs = 20\n",
    "\n",
    "    size = 1000\n",
    "    dim = 2\n",
    "\n",
    "    h_dim1 = dim\n",
    "    h_dim2 = dim\n",
    "\n",
    "    dim = data.shape[1]\n",
    "    size = data.shape[0]\n",
    "    \n",
    "    #loss = nn.BCEWithLogitsLoss(reduction = 'sum')\n",
    "    loss = nn.BCELoss(reduction = 'none')\n",
    "     \n",
    "    #for w in net_D.parameters():\n",
    "    #    nn.init.normal_(w, 0, 0.02)\n",
    "    #for w in net_G.parameters():\n",
    "    #    nn.init.normal_(w, 0, 0.02)\n",
    "\n",
    "\n",
    "    #optimizer_D = torch.optim.SGD(net_D.parameters(), lr = lr_D)\n",
    "    #optimizer_G = torch.optim.SGD(net_G.parameters(), lr = lr_G)\n",
    "\n",
    "    optimizer_D = torch.optim.Adam(net_D.parameters(), lr = lr_D)\n",
    "    optimizer_G = torch.optim.Adam(net_G.parameters(), lr = lr_G)\n",
    "\n",
    "    \n",
    "    pbar = tqdm(range(num_epochs))\n",
    "    for epoch in pbar:\n",
    "        for batch in data_iter:\n",
    "            batch_size = batch.shape[0]\n",
    "\n",
    "            mask = torch.from_numpy(np.where(batch == 0, 0.0, 1.0))\n",
    "            hint = generate_hint(mask, hint_rate)\n",
    "\n",
    "            #Z = torch.normal(0, 1, size=(batch_size, dim))\n",
    "            Z = torch.rand((batch_size, dim)) / 0.01\n",
    "            loss_D = update_D(batch, mask, hint, Z, net_D, net_G, loss, optimizer_D, alpha)\n",
    "            loss_G = update_G(batch, mask, hint, Z, net_D, net_G, loss, optimizer_G, alpha)\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            s = \"{:6d}) loss D {:0.3f} loss G {:0.3f}\".format(\n",
    "                epoch,\n",
    "                loss_D.detach().numpy(),\n",
    "                loss_G.detach().numpy())\n",
    "            pbar.clear()\n",
    "            #logger.info('{}'.format(s))\n",
    "            pbar.set_description(s)\n",
    "\n",
    "        #Z = torch.normal(0,1,(size, dim))\n",
    "        Z = torch.rand((size, dim)) / 0.01\n",
    "\n",
    "        mask = torch.from_numpy(np.where(data == 0, 0.0, 1.0))\n",
    "        hint = generate_hint(mask, hint_rate)\n",
    "\n",
    "        new_X = mask * data + (1-mask) * Z \n",
    "        input_G = torch.cat((new_X, mask), 1).float()\n",
    "        sample_G = net_G(input_G)\n",
    "\n",
    "        #fake_X = torch.from_numpy(data) * mask + sample_G * (1-mask)\n",
    "        fake_X = data * mask + sample_G * (1-mask)\n",
    "\n",
    "        loss_D = update_D(data, mask, hint, Z, net_D, net_G, loss, optimizer_D, alpha)\n",
    "        loss_G = update_G(data, mask, hint, Z, net_D, net_G, loss, optimizer_G, alpha)\n",
    "\n",
    "    \n",
    "    return loss_D, loss_G\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"missing_dist.csv\")\n",
    "features = list(df.columns)\n",
    "data = df.values\n",
    "\n",
    "mask = np.where(np.isnan(data), 0.0, 1.0)\n",
    "data = np.where(mask, data, 0.0)\n",
    "#print(data)\n",
    "\n",
    "lr_D = 0.001\n",
    "lr_G = 0.001\n",
    "\n",
    "dim = data.shape[1]\n",
    "size = data.shape[0]\n",
    "miss_rate = 0.2\n",
    "hint_rate = 0.9\n",
    "alpha = 0.2\n",
    "batch_size = 128\n",
    "num_epochs = 2000\n",
    "\n",
    "size = 5000\n",
    "dim = 2\n",
    "\n",
    "h_dim1 = dim\n",
    "h_dim2 = dim\n",
    "\n",
    "\n",
    "#X = torch.normal(0.0, 1, (size, dim))\n",
    "#A = torch.tensor([[1,2], [-0.1, 0.5]])\n",
    "#b = torch.tensor([0,0])\n",
    "#data = torch.matmul(X, A) + b\n",
    "#mask = generate_mask(data, miss_rate)\n",
    "#hint = generate_hint(mask, hint_rate)\n",
    "#data = data*mask\n",
    "\n",
    "#print(data)\n",
    "\n",
    "#d2l.set_figsize((5,5))\n",
    "#d2l.plt.scatter(data[:100, (0)].detach().numpy(), data[:100, (1)].detach().numpy())\n",
    "#d2l.plt.hist(data)\n",
    "#print(f'The covariance matrix is\\n{torch.matmul(A.T, A)}')\n",
    "\n",
    "data_iter = torch.utils.data.DataLoader(data, batch_size, shuffle=True)\n",
    "\n",
    "net_G = nn.Sequential(\n",
    "    nn.Linear(dim*2, h_dim1), nn.ReLU(),\n",
    "    nn.Linear(h_dim1, h_dim2), nn.ReLU(),\n",
    "    nn.Linear(h_dim2, dim), nn.Sigmoid())\n",
    "\n",
    "net_D = nn.Sequential(\n",
    "    nn.Linear(dim*2, h_dim1), nn.ReLU(),\n",
    "    nn.Linear(h_dim1, h_dim2), nn.ReLU(),\n",
    "    nn.Linear(h_dim2, dim), nn.Sigmoid())\n",
    "\n",
    "train(net_D, net_G, lr_D, lr_G, data_iter, num_epochs, data, hint_rate, alpha)\n",
    "\n",
    "#study = optuna.create_study(directions=[\"minimize\", \"minimize\"])\n",
    "#study.optimize(objective, n_trials=1000)\n",
    "\n",
    "#data = torch.where(data == 0, float('nan'), data)\n",
    "#df = pd.DataFrame(data)\n",
    "#df.to_csv(\"my_missing.csv\", index=False)\n",
    "#df.to_csv(\"missing_dist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trials on the Pareto front: 12\n",
      "Trial with highest accuracy: \n",
      "\tnumber: 13\n",
      "\tparams: {'lr_D': 0.06734943837301482, 'lr_G': 0.007092001564598319, 'hint_rate': 0.8574708312231205, 'alpha': 0.4279746567186455}\n",
      "\tvalues: [0.2199554741382599, 0.9027137371674904]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mvalues: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_with_highest_accuracy\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_pareto_front(study, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_param_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_D\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/visualization/_param_importances.py:191\u001b[0m, in \u001b[0;36mplot_param_importances\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot hyperparameter importances.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mExample:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    A :class:`plotly.graph_objs.Figure` object.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m _imports\u001b[38;5;241m.\u001b[39mcheck()\n\u001b[0;32m--> 191\u001b[0m importances_infos \u001b[38;5;241m=\u001b[39m \u001b[43m_get_importances_infos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_importances_plot(importances_infos, study)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/visualization/_param_importances.py:82\u001b[0m, in \u001b[0;36m_get_importances_infos\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m     80\u001b[0m     target_name \u001b[38;5;241m=\u001b[39m metric_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target \u001b[38;5;28;01melse\u001b[39;00m target_name\n\u001b[1;32m     81\u001b[0m     importances_infos: \u001b[38;5;28mtuple\u001b[39m[_ImportancesInfo, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 82\u001b[0m         \u001b[43m_get_importances_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     89\u001b[0m     )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     n_objectives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mdirections)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/visualization/_param_importances.py:54\u001b[0m, in \u001b[0;36m_get_importances_info\u001b[0;34m(study, evaluator, params, target, target_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudy instance does not contain completed trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ImportancesInfo(\n\u001b[1;32m     48\u001b[0m         importance_values\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     49\u001b[0m         param_names\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     50\u001b[0m         importance_labels\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m     51\u001b[0m         target_name\u001b[38;5;241m=\u001b[39mtarget_name,\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_param_importances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mitems())))\n\u001b[1;32m     59\u001b[0m importance_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(importances\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/__init__.py:108\u001b[0m, in \u001b[0;36mget_param_importances\u001b[0;34m(study, evaluator, params, target, normalize)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, BaseImportanceEvaluator):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluator must be a subclass of BaseImportanceEvaluator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m    110\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(res\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_evaluator.py:127\u001b[0m, in \u001b[0;36mFanovaImportanceEvaluator.evaluate\u001b[0;34m(self, study, params, target)\u001b[0m\n\u001b[1;32m    119\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluator\n\u001b[1;32m    120\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    121\u001b[0m     X\u001b[38;5;241m=\u001b[39mtrans_params,\n\u001b[1;32m    122\u001b[0m     y\u001b[38;5;241m=\u001b[39mtarget_values,\n\u001b[1;32m    123\u001b[0m     search_spaces\u001b[38;5;241m=\u001b[39mtrans\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[1;32m    124\u001b[0m     column_to_encoded_columns\u001b[38;5;241m=\u001b[39mtrans\u001b[38;5;241m.\u001b[39mcolumn_to_encoded_columns,\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m param_importances \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 127\u001b[0m     [evaluator\u001b[38;5;241m.\u001b[39mget_importance(i)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(non_single_distributions))]\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    129\u001b[0m param_importances \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39msum(param_importances)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sort_dict_by_importance(\n\u001b[1;32m    132\u001b[0m     {\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_param_importances_to_dict(non_single_distributions\u001b[38;5;241m.\u001b[39mkeys(), param_importances),\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_param_importances_to_dict(single_distributions\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;241m0.0\u001b[39m),\n\u001b[1;32m    135\u001b[0m     }\n\u001b[1;32m    136\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_evaluator.py:127\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluator\n\u001b[1;32m    120\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    121\u001b[0m     X\u001b[38;5;241m=\u001b[39mtrans_params,\n\u001b[1;32m    122\u001b[0m     y\u001b[38;5;241m=\u001b[39mtarget_values,\n\u001b[1;32m    123\u001b[0m     search_spaces\u001b[38;5;241m=\u001b[39mtrans\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[1;32m    124\u001b[0m     column_to_encoded_columns\u001b[38;5;241m=\u001b[39mtrans\u001b[38;5;241m.\u001b[39mcolumn_to_encoded_columns,\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m param_importances \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 127\u001b[0m     [\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(non_single_distributions))]\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    129\u001b[0m param_importances \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39msum(param_importances)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sort_dict_by_importance(\n\u001b[1;32m    132\u001b[0m     {\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_param_importances_to_dict(non_single_distributions\u001b[38;5;241m.\u001b[39mkeys(), param_importances),\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_param_importances_to_dict(single_distributions\u001b[38;5;241m.\u001b[39mkeys(), \u001b[38;5;241m0.0\u001b[39m),\n\u001b[1;32m    135\u001b[0m     }\n\u001b[1;32m    136\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_fanova.py:84\u001b[0m, in \u001b[0;36m_Fanova.get_importance\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trees \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variances \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_variances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m fractions: Union[List[\u001b[38;5;28mfloat\u001b[39m], numpy\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree_index, tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trees):\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_fanova.py:110\u001b[0m, in \u001b[0;36m_Fanova._compute_variances\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m    107\u001b[0m variances \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trees), dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree_index, tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trees):\n\u001b[0;32m--> 110\u001b[0m     marginal_variance \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_marginal_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     variances[tree_index] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mclip(marginal_variance, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variances[feature] \u001b[38;5;241m=\u001b[39m variances\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_tree.py:70\u001b[0m, in \u001b[0;36m_FanovaTree.get_marginal_variance\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m midpoints, sizes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(product_midpoints, product_sizes):\n\u001b[1;32m     68\u001b[0m     sample[features] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(midpoints)\n\u001b[0;32m---> 70\u001b[0m     value, weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_marginalized_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(numpy\u001b[38;5;241m.\u001b[39mprod(sizes))\n\u001b[1;32m     73\u001b[0m     values \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mappend(values, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_tree.py:112\u001b[0m, in \u001b[0;36m_FanovaTree._get_marginalized_statistics\u001b[0;34m(self, feature_vector)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_split_threshold(node_index):\n\u001b[1;32m    111\u001b[0m     next_node_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_left_child(node_index)\n\u001b[0;32m--> 112\u001b[0m     next_subspace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_left_child_subspaces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_spaces\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     next_node_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_right_child(node_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/optuna/importance/_fanova/_tree.py:283\u001b[0m, in \u001b[0;36m_FanovaTree._get_node_left_child_subspaces\u001b[0;34m(self, node_index, search_spaces)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_node_left_child_subspaces\u001b[39m(\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m, node_index: \u001b[38;5;28mint\u001b[39m, search_spaces: numpy\u001b[38;5;241m.\u001b[39mndarray\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_subspaces\u001b[49m(\n\u001b[1;32m    284\u001b[0m         search_spaces,\n\u001b[1;32m    285\u001b[0m         search_spaces_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    286\u001b[0m         feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_split_feature(node_index),\n\u001b[1;32m    287\u001b[0m         threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_split_threshold(node_index),\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Number of trials on the Pareto front: {len(study.best_trials)}\")\n",
    "\n",
    "trial_with_highest_accuracy = max(study.best_trials, key=lambda t: t.values[1])\n",
    "print(f\"Trial with highest accuracy: \")\n",
    "print(f\"\\tnumber: {trial_with_highest_accuracy.number}\")\n",
    "print(f\"\\tparams: {trial_with_highest_accuracy.params}\")\n",
    "print(f\"\\tvalues: {trial_with_highest_accuracy.values}\")\n",
    "\n",
    "optuna.visualization.plot_pareto_front(study, target_names=[\"D\", \"G\"])\n",
    "optuna.visualization.plot_param_importances(study, target=lambda t: t.values[0], target_name=\"lr_D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
